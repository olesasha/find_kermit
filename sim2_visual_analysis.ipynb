{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Feature Analyses SIM 2 - Detecting Pigs and the Swedish Chef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the visual feature analysis for the Similarity Modeling 2 project. The objective is to detect the presence of all pigs and the swedish chef, in a frame using visual features. These features are extracted using the methods outlined below. For the classification task, we employ a Naive Bayes algorithm combined with a nested cross-validation approach. Similar to Similarity Modeling 1 we implement a LightGBM Model with the aim of analyzing the performance of this model for all three subtasks (visual, audio, visual + audio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.load_data import check_and_load\n",
    "from scripts.extract_video_features import extract_lbp_features, extract_dct_features, extract_hsv_features\n",
    "from scripts.nested_cv import partition_feature_df\n",
    "\n",
    "import os\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgb2hsv\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy.fftpack import dct\n",
    "from skimage.util import img_as_ubyte\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define paths\n",
    "# data_path = \"../ground_truth_data/trimmed_videos\"\n",
    "# frames_output_dir = \"../ground_truth_data/trimmed_videos/frames\"\n",
    "# audio_output_dir = \"../ground_truth_data/trimmed_videos/audio\"\n",
    "# annotations_path = \"../ground_truth_data/trimmed_videos\"\n",
    "\n",
    "data_path = \"../ground_truth_data\"\n",
    "frames_output_dir = \"../ground_truth_data/frames\"\n",
    "audio_output_dir = \"../ground_truth_data/audio\"\n",
    "annotations_path = \"../ground_truth_data\"\n",
    "\n",
    "muppet_files = {\n",
    "    \"Muppets-02-01-01.avi\": \"GroundTruth_Muppets-02-01-01.csv\",\n",
    "    \"Muppets-02-04-04.avi\": \"GroundTruth_Muppets-02-04-04.csv\",\n",
    "    \"Muppets-03-04-03.avi\": \"GroundTruth_Muppets-03-04-03.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames and audio are already extracted.\n",
      "Loading audio segments...\n",
      "Loaded 3 audio files.\n",
      "Loaded audio segments for 3 videos.\n",
      "Loaded frames for 3 videos.\n",
      "Number of videos with frames: 3\n",
      "Video 0 has 38681 frames.\n",
      "Video 1 has 38706 frames.\n",
      "Video 2 has 38498 frames.\n"
     ]
    }
   ],
   "source": [
    "annotations, audio_data, frames = check_and_load(data_path, frames_output_dir, audio_output_dir, annotations_path, muppet_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section outlines the extraction of meaningful visual features from the video frames for the classification task. The goal is to transform raw image data into a structured format that highlights key patterns and properties essential for detecting and analyzing the presence of the pigs and the swedish chef in the videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Patterns (LBP)\n",
    "LBP is a texture descriptor that captures local patterns by encoding pixel intensity relationships within a 3x3 neighborhood. It is particularly useful for identifying repetitive structures like textures or edges. We first convert the frames to grayscale to reduce computational complexity. Next, a circular LBP operator is applied to analyze a pixel's neighborhood and generate a binary pattern. Finally, we calculate a histogram of the LBP values to summarize the texture distribution for each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115885, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lbp_features_df = extract_lbp_features(frames) # function saves df to ../model_vars/sim2_video/lbp_feature_df.csv - change parameter output_path if needed\n",
    "\n",
    "# load features if already computed\n",
    "lbp_features_df = pd.read_csv(\"../model_vars/sim2_video/lbp_feature_df.csv\")\n",
    "\n",
    "lbp_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO add vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Cosine Transform (DCT)\n",
    "DCT captures frequency domain information, emphasizing patterns in varying spatial frequencies. This method is commonly used in image compression and feature extraction due to its ability to retain critical information while reducing dimensionality. Similar to LBP the frames are converted to grayscale, then a 2D DCT is applied to each frame, and the top-left coefficients (low frequencies) are retained. These coefficients represent the dominant structural information in the image, ignoring fine details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115885, 66)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dct_features_df = extract_dct_features(frames)\n",
    "\n",
    "#load features if already computed\n",
    "dct_features_df = pd.read_csv('../model_vars/sim2_video/dct_feature_df.csv')\n",
    "\n",
    "dct_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO add vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV Color Histograms - supplemental\n",
    "Though this technique was discussed in similarity modeling 1, we borrowed this feature engineering method, in order to make use of the colors of the chracters. HSV (Hue, Saturation, Value) provides a representation of color, separating chromatic information (hue and saturation) from intensity (value). This approach is effective in distinguishing objects based on their color characteristics - such as the pink of the pigs. We convert the frames to the HSV color space and compute histograms for each channel (H, S, and V), capturing the distribution of colors in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115885, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Color Histogram features\n",
    "#hsv_feature_df = extract_hsv_features(frames)\n",
    "\n",
    "#load features if already computed\n",
    "hsv_feature_df = pd.read_csv('../model_vars/sim2_video/hsv_feature_df.csv')\n",
    " \n",
    "hsv_feature_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO add vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115885, 124)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames on 'video_idx' and 'frame_idx'\n",
    "#merged_df = lbp_features_df.merge(dct_features_df, on=[\"video_idx\", \"frame_idx\"], how=\"inner\")\n",
    "#merged_df = merged_df.merge(hsv_feature_df, on=[\"video_idx\", \"frame_idx\"], how=\"inner\")\n",
    "\n",
    "output_path_merged = \"../model_vars/sim2_video/merged_df.csv\"\n",
    "#merged_df.to_csv(output_path_merged, index=False)\n",
    "\n",
    "merged_df = pd.read_csv(output_path_merged)\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115885, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from filenames to video indices\n",
    "video_idx_map = {filename: idx for idx, filename in enumerate(muppet_files.keys())}\n",
    "\n",
    "# Prepare ground truth data with corrected video_idx\n",
    "ground_truth_data = []\n",
    "for video_filename, annotation_df in annotations.items():\n",
    "    video_idx = video_idx_map[video_filename]  # Map video filename to its index\n",
    "    for _, row in annotation_df.iterrows():\n",
    "        ground_truth_data.append({\n",
    "            'video_idx': video_idx,  # Use mapped video index\n",
    "            'frame_idx': row['Frame_number'],  # Assuming Frame_number exists\n",
    "            'Pigs': row['Pigs'],  # Assuming Pigs is a column in the annotation\n",
    "            'Cook': row['Cook']  # Assuming this column exists\n",
    "        })\n",
    "\n",
    "# Create a DataFrame for ground truth\n",
    "ground_truth_df = pd.DataFrame(ground_truth_data)\n",
    "ground_truth_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115885, 126)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge features with ground truth\n",
    "feature_df = pd.merge(merged_df, ground_truth_df, on=['video_idx', 'frame_idx'], how='inner')\n",
    "feature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115885, 127)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split_points = {\n",
    "#     0: 19716,  # Video 0\n",
    "#     1: 19719,  # Video 1\n",
    "#     2: 19432, # Video 2 \n",
    "# }\n",
    "\n",
    "# Assuming feature_df is the dataframe containing video_idx and frame_idx columns\n",
    "grp_by = ['Pigs', 'Cook']\n",
    "feature_df, split_overview = partition_feature_df(feature_df, grp_by = grp_by)\n",
    "\n",
    "output_path_feature = \"../model_vars/sim2_video/feature_df.csv\"\n",
    "feature_df.to_csv(output_path_feature, index=False)\n",
    "\n",
    "#feature_df = pd.read_csv(output_path_feature)\n",
    "feature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbp_bin_0</th>\n",
       "      <th>lbp_bin_1</th>\n",
       "      <th>lbp_bin_2</th>\n",
       "      <th>lbp_bin_3</th>\n",
       "      <th>lbp_bin_4</th>\n",
       "      <th>lbp_bin_5</th>\n",
       "      <th>lbp_bin_6</th>\n",
       "      <th>lbp_bin_7</th>\n",
       "      <th>lbp_bin_8</th>\n",
       "      <th>lbp_bin_9</th>\n",
       "      <th>...</th>\n",
       "      <th>hsv_channel_2_bin_9</th>\n",
       "      <th>hsv_channel_2_bin_10</th>\n",
       "      <th>hsv_channel_2_bin_11</th>\n",
       "      <th>hsv_channel_2_bin_12</th>\n",
       "      <th>hsv_channel_2_bin_13</th>\n",
       "      <th>hsv_channel_2_bin_14</th>\n",
       "      <th>hsv_channel_2_bin_15</th>\n",
       "      <th>Pigs</th>\n",
       "      <th>Cook</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lbp_bin_0  lbp_bin_1  lbp_bin_2  lbp_bin_3  lbp_bin_4  lbp_bin_5  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   lbp_bin_6  lbp_bin_7  lbp_bin_8  lbp_bin_9  ...  hsv_channel_2_bin_9  \\\n",
       "0        0.0        0.0        1.0        0.0  ...                  0.0   \n",
       "1        0.0        0.0        1.0        0.0  ...                  0.0   \n",
       "2        0.0        0.0        1.0        0.0  ...                  0.0   \n",
       "3        0.0        0.0        1.0        0.0  ...                  0.0   \n",
       "4        0.0        0.0        1.0        0.0  ...                  0.0   \n",
       "\n",
       "   hsv_channel_2_bin_10  hsv_channel_2_bin_11  hsv_channel_2_bin_12  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   hsv_channel_2_bin_13  hsv_channel_2_bin_14  hsv_channel_2_bin_15  Pigs  \\\n",
       "0                   0.0                   0.0                   0.0     0   \n",
       "1                   0.0                   0.0                   0.0     0   \n",
       "2                   0.0                   0.0                   0.0     0   \n",
       "3                   0.0                   0.0                   0.0     0   \n",
       "4                   0.0                   0.0                   0.0     0   \n",
       "\n",
       "   Cook  fold  \n",
       "0     0   0-A  \n",
       "1     0   0-A  \n",
       "2     0   0-A  \n",
       "3     0   0-A  \n",
       "4     0   0-A  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   video_idx fold  Pigs  Cook\n",
      "0          0  0-A  1871   217\n",
      "1          0  0-B     0  1654\n",
      "2          1  1-A  4012   226\n",
      "3          1  1-B  4769     0\n",
      "4          2  2-A  5134   683\n",
      "5          2  2-B  5694   665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0-A', '0-B', '1-A', '1-B', '2-A', '2-B'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results\n",
    "print(split_overview)\n",
    "\n",
    "feature_df['fold'].unique() # ACHTUNG manche fehlen in den Splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in any feature: False\n",
      "Inf in any numeric feature: False\n",
      "Rows with Inf values: []\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df = feature_df.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "print(\"NaN in any feature:\", feature_df.isnull().values.any())\n",
    "# Check for infinite values in numeric columns\n",
    "print(\"Inf in any numeric feature:\", np.isinf(numeric_df.values).any())\n",
    "\n",
    "# Optionally, find rows with infinite values\n",
    "rows_with_inf = numeric_df[np.isinf(numeric_df).any(axis=1)].index.tolist()\n",
    "print(\"Rows with Inf values:\", rows_with_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of physical cores: 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.nested_cv import evaluate_model, nested_cross_validation\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "physical_cores = psutil.cpu_count(logical=False)\n",
    "print(f\"Number of physical cores: {physical_cores}\")\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('../model_vars/sim2_video/feature_df.csv')\n",
    "\n",
    "\n",
    "train_cols = [col for col in feature_df.columns if col.startswith(('lbp', 'hsv', 'dct'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbp_bin_0</th>\n",
       "      <th>lbp_bin_1</th>\n",
       "      <th>lbp_bin_2</th>\n",
       "      <th>lbp_bin_3</th>\n",
       "      <th>lbp_bin_4</th>\n",
       "      <th>lbp_bin_5</th>\n",
       "      <th>lbp_bin_6</th>\n",
       "      <th>lbp_bin_7</th>\n",
       "      <th>lbp_bin_8</th>\n",
       "      <th>lbp_bin_9</th>\n",
       "      <th>...</th>\n",
       "      <th>hsv_channel_2_bin_8</th>\n",
       "      <th>hsv_channel_2_bin_9</th>\n",
       "      <th>hsv_channel_2_bin_10</th>\n",
       "      <th>hsv_channel_2_bin_11</th>\n",
       "      <th>hsv_channel_2_bin_12</th>\n",
       "      <th>hsv_channel_2_bin_13</th>\n",
       "      <th>hsv_channel_2_bin_14</th>\n",
       "      <th>hsv_channel_2_bin_15</th>\n",
       "      <th>Pigs</th>\n",
       "      <th>Cook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "      <td>115885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.038826</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>0.085142</td>\n",
       "      <td>0.151472</td>\n",
       "      <td>0.230323</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.047366</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.049892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072261</td>\n",
       "      <td>0.953754</td>\n",
       "      <td>0.828437</td>\n",
       "      <td>0.712243</td>\n",
       "      <td>0.527304</td>\n",
       "      <td>0.338847</td>\n",
       "      <td>0.221629</td>\n",
       "      <td>0.203214</td>\n",
       "      <td>0.185356</td>\n",
       "      <td>0.029728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.023469</td>\n",
       "      <td>0.055371</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>0.012952</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.137520</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700995</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.822851</td>\n",
       "      <td>0.663433</td>\n",
       "      <td>0.460252</td>\n",
       "      <td>0.331332</td>\n",
       "      <td>0.443309</td>\n",
       "      <td>0.388588</td>\n",
       "      <td>0.169836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.032616</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.071089</td>\n",
       "      <td>0.114698</td>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.210585</td>\n",
       "      <td>0.043814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598243</td>\n",
       "      <td>0.433292</td>\n",
       "      <td>0.297752</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.115266</td>\n",
       "      <td>0.064257</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.023061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.038689</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.087530</td>\n",
       "      <td>0.158467</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.055560</td>\n",
       "      <td>0.048019</td>\n",
       "      <td>0.283731</td>\n",
       "      <td>0.049599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955637</td>\n",
       "      <td>0.771098</td>\n",
       "      <td>0.596925</td>\n",
       "      <td>0.417279</td>\n",
       "      <td>0.281822</td>\n",
       "      <td>0.186111</td>\n",
       "      <td>0.114890</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.013261</td>\n",
       "      <td>0.044996</td>\n",
       "      <td>0.025380</td>\n",
       "      <td>0.100518</td>\n",
       "      <td>0.194563</td>\n",
       "      <td>0.253705</td>\n",
       "      <td>0.062576</td>\n",
       "      <td>0.053682</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350476</td>\n",
       "      <td>1.172585</td>\n",
       "      <td>0.972100</td>\n",
       "      <td>0.858088</td>\n",
       "      <td>0.646432</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.268791</td>\n",
       "      <td>0.205025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.042604</td>\n",
       "      <td>0.222249</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>0.146134</td>\n",
       "      <td>0.271931</td>\n",
       "      <td>0.460948</td>\n",
       "      <td>0.090126</td>\n",
       "      <td>0.216194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.356191</td>\n",
       "      <td>...</td>\n",
       "      <td>7.688644</td>\n",
       "      <td>11.281291</td>\n",
       "      <td>6.124551</td>\n",
       "      <td>7.989216</td>\n",
       "      <td>4.902741</td>\n",
       "      <td>3.509804</td>\n",
       "      <td>4.298856</td>\n",
       "      <td>15.792565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lbp_bin_0      lbp_bin_1      lbp_bin_2      lbp_bin_3  \\\n",
       "count  115885.000000  115885.000000  115885.000000  115885.000000   \n",
       "mean        0.010907       0.038826       0.020460       0.085142   \n",
       "std         0.003762       0.011804       0.007544       0.023469   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.008638       0.032616       0.015663       0.071089   \n",
       "50%         0.010828       0.038689       0.020450       0.087530   \n",
       "75%         0.013261       0.044996       0.025380       0.100518   \n",
       "max         0.042604       0.222249       0.049828       0.146134   \n",
       "\n",
       "           lbp_bin_4      lbp_bin_5      lbp_bin_6      lbp_bin_7  \\\n",
       "count  115885.000000  115885.000000  115885.000000  115885.000000   \n",
       "mean        0.151472       0.230323       0.054135       0.047366   \n",
       "std         0.055371       0.049187       0.012952       0.011772   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.114698       0.207644       0.047393       0.041565   \n",
       "50%         0.158467       0.231000       0.055560       0.048019   \n",
       "75%         0.194563       0.253705       0.062576       0.053682   \n",
       "max         0.271931       0.460948       0.090126       0.216194   \n",
       "\n",
       "           lbp_bin_8      lbp_bin_9  ...  hsv_channel_2_bin_8  \\\n",
       "count  115885.000000  115885.000000  ...        115885.000000   \n",
       "mean        0.311475       0.049892  ...             1.072261   \n",
       "std         0.137520       0.013403  ...             0.700995   \n",
       "min         0.089293       0.000000  ...             0.000000   \n",
       "25%         0.210585       0.043814  ...             0.598243   \n",
       "50%         0.283731       0.049599  ...             0.955637   \n",
       "75%         0.375763       0.056000  ...             1.350476   \n",
       "max         1.000000       0.356191  ...             7.688644   \n",
       "\n",
       "       hsv_channel_2_bin_9  hsv_channel_2_bin_10  hsv_channel_2_bin_11  \\\n",
       "count        115885.000000         115885.000000         115885.000000   \n",
       "mean              0.953754              0.828437              0.712243   \n",
       "std               0.902687              0.793313              0.822851   \n",
       "min               0.000000              0.000000              0.000000   \n",
       "25%               0.433292              0.297752              0.208333   \n",
       "50%               0.771098              0.596925              0.417279   \n",
       "75%               1.172585              0.972100              0.858088   \n",
       "max              11.281291              6.124551              7.989216   \n",
       "\n",
       "       hsv_channel_2_bin_12  hsv_channel_2_bin_13  hsv_channel_2_bin_14  \\\n",
       "count         115885.000000         115885.000000         115885.000000   \n",
       "mean               0.527304              0.338847              0.221629   \n",
       "std                0.663433              0.460252              0.331332   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.115266              0.064257              0.033783   \n",
       "50%                0.281822              0.186111              0.114890   \n",
       "75%                0.646432              0.421650              0.268791   \n",
       "max                4.902741              3.509804              4.298856   \n",
       "\n",
       "       hsv_channel_2_bin_15           Pigs           Cook  \n",
       "count         115885.000000  115885.000000  115885.000000  \n",
       "mean               0.203214       0.185356       0.029728  \n",
       "std                0.443309       0.388588       0.169836  \n",
       "min                0.000000       0.000000       0.000000  \n",
       "25%                0.023061       0.000000       0.000000  \n",
       "50%                0.086969       0.000000       0.000000  \n",
       "75%                0.205025       0.000000       0.000000  \n",
       "max               15.792565       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 126 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lbp_bin_0', 'lbp_bin_1', 'lbp_bin_2', 'lbp_bin_3', 'lbp_bin_4', 'lbp_bin_5', 'lbp_bin_6', 'lbp_bin_7', 'lbp_bin_8', 'lbp_bin_9', 'dct_coeff_0', 'dct_coeff_1', 'dct_coeff_2', 'dct_coeff_3', 'dct_coeff_4', 'dct_coeff_5', 'dct_coeff_6', 'dct_coeff_7', 'dct_coeff_8', 'dct_coeff_9', 'dct_coeff_10', 'dct_coeff_11', 'dct_coeff_12', 'dct_coeff_13', 'dct_coeff_14', 'dct_coeff_15', 'dct_coeff_16', 'dct_coeff_17', 'dct_coeff_18', 'dct_coeff_19', 'dct_coeff_20', 'dct_coeff_21', 'dct_coeff_22', 'dct_coeff_23', 'dct_coeff_24', 'dct_coeff_25', 'dct_coeff_26', 'dct_coeff_27', 'dct_coeff_28', 'dct_coeff_29', 'dct_coeff_30', 'dct_coeff_31', 'dct_coeff_32', 'dct_coeff_33', 'dct_coeff_34', 'dct_coeff_35', 'dct_coeff_36', 'dct_coeff_37', 'dct_coeff_38', 'dct_coeff_39', 'dct_coeff_40', 'dct_coeff_41', 'dct_coeff_42', 'dct_coeff_43', 'dct_coeff_44', 'dct_coeff_45', 'dct_coeff_46', 'dct_coeff_47', 'dct_coeff_48', 'dct_coeff_49', 'dct_coeff_50', 'dct_coeff_51', 'dct_coeff_52', 'dct_coeff_53', 'dct_coeff_54', 'dct_coeff_55', 'dct_coeff_56', 'dct_coeff_57', 'dct_coeff_58', 'dct_coeff_59', 'dct_coeff_60', 'dct_coeff_61', 'dct_coeff_62', 'dct_coeff_63', 'hsv_channel_0_bin_0', 'hsv_channel_0_bin_1', 'hsv_channel_0_bin_2', 'hsv_channel_0_bin_3', 'hsv_channel_0_bin_4', 'hsv_channel_0_bin_5', 'hsv_channel_0_bin_6', 'hsv_channel_0_bin_7', 'hsv_channel_0_bin_8', 'hsv_channel_0_bin_9', 'hsv_channel_0_bin_10', 'hsv_channel_0_bin_11', 'hsv_channel_0_bin_12', 'hsv_channel_0_bin_13', 'hsv_channel_0_bin_14', 'hsv_channel_0_bin_15', 'hsv_channel_1_bin_0', 'hsv_channel_1_bin_1', 'hsv_channel_1_bin_2', 'hsv_channel_1_bin_3', 'hsv_channel_1_bin_4', 'hsv_channel_1_bin_5', 'hsv_channel_1_bin_6', 'hsv_channel_1_bin_7', 'hsv_channel_1_bin_8', 'hsv_channel_1_bin_9', 'hsv_channel_1_bin_10', 'hsv_channel_1_bin_11', 'hsv_channel_1_bin_12', 'hsv_channel_1_bin_13', 'hsv_channel_1_bin_14', 'hsv_channel_1_bin_15', 'hsv_channel_2_bin_0', 'hsv_channel_2_bin_1', 'hsv_channel_2_bin_2', 'hsv_channel_2_bin_3', 'hsv_channel_2_bin_4', 'hsv_channel_2_bin_5', 'hsv_channel_2_bin_6', 'hsv_channel_2_bin_7', 'hsv_channel_2_bin_8', 'hsv_channel_2_bin_9', 'hsv_channel_2_bin_10', 'hsv_channel_2_bin_11', 'hsv_channel_2_bin_12', 'hsv_channel_2_bin_13', 'hsv_channel_2_bin_14', 'hsv_channel_2_bin_15']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_cols)\n",
    "len(train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis, we employ a nested cross-validation approach for our classification models. The nested cross-validation provides robust model evaluation by incorporating two levels of data splitting: an outer loop for testing model generalization and an inner loop for hyperparameter tuning. The outer loop ensures that the performance metrics reflect how well the model generalizes to entirely unseen data, while the inner loop systematically optimizes the model's parameters using the training data.\n",
    "\n",
    "A traditional random train-test split could lead to data leakage if frames from the same video appear in both the training and testing sets. This overlap could inflate performance metrics by allowing the model to learn video-specific features rather than generalizable patterns. The nested cross-validation mitigates this risk by ensuring that the outer splits isolate data from different videos, providing a more realistic estimate of the model's ability to generalize across unseen scenarios. \n",
    "\n",
    "For the creation of the folds, each episode is split at its midway point, specifically at the transition where a segment ends and the screen briefly fades to black before the next segment begins. This results in two distinct folds per episode, ensuring that each fold captures a separate and coherent part of the episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Fold 0-A: {'outer_fold': '0-A', 'accuracy': 0.5234327449786975, 'precision': np.float64(0.8973781262834788), 'recall': np.float64(0.5234327449786975), 'f1': np.float64(0.611644589366598), 'roc_auc': np.float64(0.8487717815939532)}\n",
      "Metrics for Fold 1-A: {'outer_fold': '1-A', 'accuracy': 0.6932907348242812, 'precision': np.float64(0.7736492540280212), 'recall': np.float64(0.6932907348242812), 'f1': np.float64(0.7188984654563997), 'roc_auc': np.float64(0.7155395959571467)}\n",
      "Metrics for Fold 1-B: {'outer_fold': '1-B', 'accuracy': 0.6257965976720914, 'precision': np.float64(0.6393746689500284), 'recall': np.float64(0.6257965976720914), 'f1': np.float64(0.6321678309054406), 'roc_auc': np.float64(0.6427215747031788)}\n",
      "Metrics for Fold 2-A: {'outer_fold': '2-A', 'accuracy': 0.49639769452449567, 'precision': np.float64(0.6944319709785657), 'recall': np.float64(0.49639769452449567), 'f1': np.float64(0.5133877640961363), 'roc_auc': np.float64(0.7358976928458588)}\n",
      "Metrics for Fold 2-B: {'outer_fold': '2-B', 'accuracy': 0.48751704605056123, 'precision': np.float64(0.5576673350538448), 'recall': np.float64(0.48751704605056123), 'f1': np.float64(0.5090177833732769), 'roc_auc': np.float64(0.4848793806181252)}\n",
      "\n",
      "Overall Summary:\n",
      "{'accuracy': 0.5652869636100254, 'precision': 0.7125002710587879, 'recall': 0.5652869636100254, 'f1': 0.5970232866395703, 'roc_auc': 0.6855620051436525}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {}\n",
    "\n",
    "feature_df_pigs = feature_df[feature_df['fold'] != \"0-B\"]\n",
    "\n",
    "target_col = 'Pigs'\n",
    "results_nb_pigs, summary_nb_pigs, best_model_nb_pigs = nested_cross_validation(\n",
    "    feature_df_pigs, \n",
    "    train_cols, \n",
    "    target_col, \n",
    "    GaussianNB, \n",
    "    param_grid, \n",
    "    num_cores=10\n",
    ")\n",
    "\n",
    "## Save Vars\n",
    "import pickle\n",
    "with open('../model_vars/sim2_video/pigs_nb_results.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'results_pigs': results_nb_pigs,\n",
    "        'summary_pigs': summary_nb_pigs,\n",
    "        'best_model_pigs': best_model_nb_pigs\n",
    "    }, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swedish Cook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Fold 0-A: {'outer_fold': '0-A', 'accuracy': 0.9831101643335363, 'precision': np.float64(0.9780441374663073), 'recall': np.float64(0.9831101643335363), 'f1': np.float64(0.9805706076543964), 'roc_auc': np.float64(0.7417421618927403)}\n",
      "Metrics for Fold 0-B: {'outer_fold': '0-B', 'accuracy': 0.9077247561297126, 'precision': np.float64(0.8327745642779932), 'recall': np.float64(0.9077247561297126), 'f1': np.float64(0.8686358901802906), 'roc_auc': np.float64(0.9156154738580365)}\n",
      "Metrics for Fold 1-A: {'outer_fold': '1-A', 'accuracy': 0.9406663623916021, 'precision': np.float64(0.9811876741594294), 'recall': np.float64(0.9406663623916021), 'f1': np.float64(0.9594712948128516), 'roc_auc': np.float64(0.8414041527954895)}\n",
      "Metrics for Fold 2-A: {'outer_fold': '2-A', 'accuracy': 0.8222519555372582, 'precision': np.float64(0.9277316281077067), 'recall': np.float64(0.8222519555372582), 'f1': np.float64(0.8712773306592072), 'roc_auc': np.float64(0.6326220463334423)}\n",
      "Metrics for Fold 2-B: {'outer_fold': '2-B', 'accuracy': 0.851201090947236, 'precision': np.float64(0.9271310095016033), 'recall': np.float64(0.851201090947236), 'f1': np.float64(0.887545050263215), 'roc_auc': np.float64(0.6147612114902222)}\n",
      "\n",
      "Overall Summary:\n",
      "{'accuracy': 0.9009908658678689, 'precision': 0.929373802702608, 'recall': 0.9009908658678689, 'f1': 0.9135000347139922, 'roc_auc': 0.7492290092739863}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {}\n",
    "\n",
    "feature_df_cook = feature_df[feature_df['fold'] != \"1-B\"]\n",
    "\n",
    "target_col = 'Cook'\n",
    "results_nb_cook, summary_nb_cook, best_model_nb_cook = nested_cross_validation(\n",
    "    feature_df_cook, \n",
    "    train_cols, \n",
    "    target_col, \n",
    "    GaussianNB, \n",
    "    param_grid, \n",
    "    num_cores=10\n",
    ")\n",
    "\n",
    "\n",
    "## Save Vars\n",
    "import pickle\n",
    "with open('../model_vars/sim2_video/cook_nb_results.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'results_cook': results_nb_cook,\n",
    "        'summary_cook': summary_nb_cook,\n",
    "        'best_model_cook': best_model_nb_cook\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB - TODO LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. GPU: NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scripts.nested_cv import ncv_xgb_gpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold: 0-A\n",
      "Outer Fold: 1-A\n",
      "Outer Fold: 1-B\n",
      "Outer Fold: 2-A\n",
      "Outer Fold: 2-B\n",
      "Model: 6/6\n",
      "Summary of Metrics Across Folds:\n",
      "{'accuracy': 0.7550947403613891, 'precision': 0.7129216497936853, 'recall': 0.7550947403613891, 'f1': 0.7087152111030657, 'roc_auc': 0.6606317907768406}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "feature_df_pigs = feature_df[feature_df['fold'] != \"0-B\"]\n",
    "feature_df_pigs.shape\n",
    "\n",
    "feature_df = pd.read_csv('../model_vars/sim2_video/feature_df.csv')\n",
    "train_cols = [col for col in feature_df.columns if col.startswith(('lbp', 'hsv', 'dct'))]\n",
    "\n",
    "target_col='Pigs'\n",
    "results_rf_kermit, summary_rf_kermit, best_models_rf_kermit = ncv_xgb_gpu(\n",
    "    feature_df=feature_df_pigs,\n",
    "    train_cols=train_cols,\n",
    "    target_col=target_col,\n",
    "    param_grid=param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Save Vars\n",
    "import pickle\n",
    "with open('../model_vars/sim1_audio/kermit_rf_results.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'results_kermit': results_rf_kermit,\n",
    "        'summary_kermit': summary_rf_kermit,\n",
    "        'best_model_kermit': best_models_rf_kermit\n",
    "    }, f)\n",
    "\n",
    "\n",
    "# print(\"Results:\", results_rf_kermit)\n",
    "# print(\"Summary:\", summary_rf_kermit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim1_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
